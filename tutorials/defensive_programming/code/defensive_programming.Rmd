---
title: "Defensive Programming in R"
author: "Sarah Cobey"
output:
  html_document: default
  pdf_document: default
---

# Defensive Programming

- **Goal:** Convince new and existing programmers of the importance of defensive programming practices, introduce general programming principles, and provide specific tips for programming and debugging in R.

- **Audience:** Scientific researchers who use `R` and believe the accuracy of their code and/or efficiency of their programming could be improved.

- **Installation:** For people who have completed the other modules, there is nothing new to install. For others starting fresh, install `R` and `RStudio`. To install `R`, follow instructions at [`cran.rstudio.com`](https://cran.rstudio.com/). Then install `Rstudio` following the instructions at [`goo.gl/a42jYE`](https://www.rstudio.com/products/rstudio/download2/). Download the `knitr` package.

# Motivation

Defensive programming is the practice of anticipating errors in your code and handling them efficiently.

If you're new to programming, defensive programming might seem at first like a tedious waste of time. But if you've been programming long, you've probably experienced firsthand the pain from

* inexplicable, strange behavior by the code
* code that seems to work under some conditions but not others
* incorrect results or bugs that take days or weeks to fix
* a program that seems to produce the correct results but then, months or years later, gives you an answer that you know must be wrong... thereby putting all previous results in doubt
* the nagging feeling that maybe there's still a bug somewhere
* not getting others' code to run or run correctly, even though you're following their instructions

Defensive programming is thus also a set of practices for preserving sanity and conducting research efficiently. It is an art, in that the best methods vary from person to person and from project to project. As you will see, which techniques you use depend on the kind of mistakes you make, who else will use your code, and the project's requirements for accuracy and robustness. But that flexibility does not imply defensive programming is "optional": steady scientific progress depends on it. In general, we need scientific code to be perfectly accurate (or at least have well understood inaccuracies), but compared to other programmers, we are less concerned with security and ensuring that completely naive users can run our programs under diverse circumstances (although standards here are changing).  

In the first part of this tutorial, we will review key principles of defensive programming for scientific researchers. These principles hold for all languages, not just `R`. In the second part, we will consider R-specific debugging practices in more depth.

# Part 1: Principles

Part 1 focuses on defense. You saw a few of these principles in [Basic Computing 2](https://github.com/StefanoAllesina/BSD-QBio3/blob/master/tutorials/basic_computing_2/code/basic_computing_2.Rmd), but they are important enough to be repeated here.

1. [Before writing code, draft your program as a series of modular functions with high-level documentation, and develop tests for it.](#principle-1-before-writing-code-draft-your-program-as-a-series-of-modular-functions-with-high-level-documentation-and-develop-tests-for-it-pr)
2. [Write clearly and cautiously.](#principle-2-write-clearly-and-cautiously)
3. [Develop one function at a time, and test it before writing another.](#principle-3-develop-one-function-at-a-time-and-test-it-before-writing-another)
4. [Document often.](#principle-4-document-often)
5. [Refactor often.](#principle-5-refactor-often)
6. [When you run your code, save each "experiment" in a separate directory with a complete copy of the code repository and all parameters.](#principle-6-when-you-run-your-code-save-each-experiment-in-a-separate-directory-with-a-complete-copy-of-the-code-repository-and-all-parameters)
7. [Don't be *too* defensive.](#principle-7-dont-be-too-defensive)

In part 2, we will focus on what to do when tests (from Principle 3) indicate something is wrong.

### Principle 1. Before writing code, draft your program as a series of modular functions with high-level documentation, and develop tests for it. {#pr1}

Many of us have had the experience of writing a long paper only to realize, several pages in, that we in fact need to say something slightly different. Restructuring a paper at this stage can be a real chore. Outlining your code as you would outline a paper avoids this problem. In fact, outlining your code can be even more helpful because it helps you think not just generally about how your algorithm will flow and where you want to end up, but also about what building blocks (functions and containers) you'll use to get there. Thinking about the "big picture" design will prevent you from coding yourself into a tight spot---when you realize hundreds of lines in that you should've been tracking past states of a variable, for instance, but your current containers are only storing the current state. Drafting also makes the actual writing much more easy and fun.

For complex programs, your draft may start as a diagram or flowchart showing how major functions and variables relate to one another or brief notes about each of step of the algorithm. These outlines are known as pseudocode, and there are myriad customs for pseudocode and programmers loyal to particular styles. For simple scripts, it is often sufficient to write pseudocode as placeholder comments. For instance, if we are simulating a population in which individuals can be born or die (and nothing else happens), we could write:

```
# initialize population size (N), birth rate (b), death rate (d), total simulation time (t_max), and time (t=0)
# while N > 0 and t < t_max
# ...generate random numbers to determine whether next event is birth or death, and time to event (dt)
# ...update N (increment if birth, decrement if death) and update time t to t+dt
```

Here, `b` and `d` are per capita rates. This is an example of the [Gillespie algorithm](https://en.wikipedia.org/wiki/Gillespie_algorithm). It was initially developed as an exact stochastic approach for simulating chemical reaction kinetics, and it is widely used in biology, chemistry, and physics. 

Can you see some weaknesses of the pseudocode so far? First, it lacks obvious modularity. The first step under the `while` loop could become its own function that is defined separately. Second, it is missing a critical feature, in that it's not obvious what is being output: do we want the population size at the end of the simulation, or the population size at each event? If the latter, we may need to initialize a container, such as a dataframe, in which we store the value of `N` and `t` at every event. After further thought, we might decide such a container would be too big---perhaps we only need to know the value of `N` at 1/1000th the typical rate of births, and so we might introduce an additional loop to store `N` only when the new time `(t+dt)` exceeds the most recent prescribed observation/sampling time. This sampling time would need to be stored in an extra variable, and we could also make the sampling procedure into its own function.

The next stage of drafting is to consider how the code might go wrong, and what it would take to convince ourselves that it is accurate. We'll spend more time on this later, but now is the time to think of every possible sanity check for the code. Sometimes this can lead to changes in code design. For instance,

* Initial values of `b`, `d`, and `t_max` should be non-negative and not change
* The population size `N` should probably start as a positive whole number and never fall below zero
* If the birth and death rates are zero, `N` should not change
* If the birth rate equals the death rate, on average, `N` should not change when it is large
* The ratio of births to deaths should equal the ratio of the birth rate to the death rate, on average
* The population should, on average, grow exponentially at rate `b-d`

Some of these criteria arise from common sense or assumptions we want to build into the model (for instance, that the birth and death rates aren't negative), and others we know from the mathematics of the system. For instance, the population cannot change if there are no births and deaths, and it must increase on average if the birth rate exceeds the death rate. It helps that the Gillespie algorithm represents kinetics that can be written as simple differential equations. However, because the simulations are stochastic, we need to look at many realizations (randomizations, trajectories) to ensure there aren't consistent biases. We can use statistics to confirm, for instance, that the distribution of `N` in 10,000 simulations after 100 time units is not significantly different from what we would predict mathematically.

The bottom line is that we have identified some tests for the (1) inputs, (2) intermediate variable states (like `N`), (3) final outputs to test that the program is running correctly. Note that one of our tests, the fraction of birth to death events, is not something we were originally tracking, and thus we might decide now to create a separate function and variables to handle these quantities. We will talk in more detail about how to implement these tests in [Principle 3](#pr3). Generally, tests of specific functions are known as **unit tests**, and tests of aggregate behavior (like the trajectories of 10,000 simulations) are known as **system tests**. As a general principle, we need to have both, and we need as much as possible to compare their outputs to analytic expectations. It is also very useful to identify what you want to see right away. For instance, you may want to write a function to plot the population size over time *before* you code anything else because the visual feedback can be extremely helpful.

This is also a good time to draft very high-level documentation for your code, for instance in a `readme.MD` file. What are the inputs, what does the code do, and what does it return?

> **Exercise**
> 
> Assume there are two discrete populations. Each has nonoverlapping generations and the same generation time. Their per capita birth rates are `b1` and `b2`. Some of the newborns migrate between populations.
> * Write pseudocode to calculate the distribution of population frequencies after 100 generations.
> * Do you think the code is optimally modular?
> * What are the inputs and outputs of the program? Of each function?
> * How could you test the inputs, functions, and overall program?
> * Compare your answers to your neighbors'.

### Principle 2. Write clearly and cautiously.

### Principle 3. Develop one function at a time, and test it before writing another.

### Principle 4. Document often.

### Principle 5. Refactor often.

### Principle 6. When you run your code, save each "experiment" in a separate directory with a complete copy of the code repository and all parameters.

### Principle 7. Don't be *too* defensive.

# Part 2: Debugging in R
